{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation criteria\n",
    "\n",
    "The goal of this assignment is to get a view on your hands-on \"data engineering\" skills.  \n",
    "At our company, our data scientists and engineers collaborate on projects.  \n",
    "Your main focus will be creating performant & robust data flows.  \n",
    "For a take-home-assignment, we cannot grant you access to our infrastructure.  \n",
    "The assignement below measures your proficiency in general programming, data science & engineering tasks using python.  \n",
    "Completion should not take more than half a day.\n",
    "\n",
    "**We expect you to be proficient in:**\n",
    " * SQL queries (Sybase IQ system)\n",
    " * ETL flows (In collaboration with existing teams)\n",
    " * General python to glue it all together\n",
    " * Python data science ecosystem (Pandas + SKlearn)\n",
    " \n",
    "**In this exercise we expect you to demonstrate your ability to / knowledge of:**\n",
    " * Building a data science runtime\n",
    " * PEP8 / Google python styleguide\n",
    " * Efficiently getting the job done\n",
    " * Choose meaningfull names for variables & functions\n",
    " * Writing maintainable code (yes, you might need to document some steps)\n",
    " * Help a data scientist present interactive results.\n",
    " * Offer predictions via REST api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting-up a data science workspace\n",
    "\n",
    "We allow you full freedom in setting up a data science runtime.  \n",
    "The main objective is having a runtime where you can run this notebook and the code you will develop.  \n",
    "You can choose for a local setup on your pc, or even a cloud setup if you're up for it.   \n",
    "\n",
    "**In your environment, you will need things for:**\n",
    " * https request\n",
    " * python3 (not python2 !!)\n",
    " * (geo)pandas\n",
    " * interactive maps (e.g. folium, altair, ...)\n",
    " * REST apis\n",
    " \n",
    "**Deliverables we expect**:\n",
    " * notebook with the completed assignment\n",
    " * list of packages for your runtime (e.g. yml or txt file)\n",
    " * evidence of a working API endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like you to put all your import statements here, together in 1 place.  \n",
    "Before submitting, please make sure you remove any unused imports :-)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your imports go here.  You get pandas for free.\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ingestion exercises\n",
    "\n",
    "## Getting store location data from an API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Obtain a pandas dataframe  \n",
    "**Hint:** You will need to normalise/flatten the json, because it contains multiple levels  \n",
    "**API call:** https://ecgplacesmw.colruytgroup.com/ecgplacesmw/v3/nl/places/filter/clp-places  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here\n",
    "\n",
    "def get_clp_places(url):\n",
    "    raise NotImplementedError(\"You need to develop this method!\")\n",
    "\n",
    "df_clp = get_clp_places(\"https://ecgplacesmw.colruytgroup.com/ecgplacesmw/v3/nl/places/filter/clp-places\")\n",
    "df_clp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality checks\n",
    "\n",
    "We would like you to add several checks on this data based on these constraints:  \n",
    " * records > 200\n",
    " * latitude between 49 and 52\n",
    " * longitude between 2 and 7\n",
    " \n",
    "We dont want you to create a full blown test suite here, we're just gonna use 'asserts' from unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here\n",
    "tc = unittest.TestCase('__init__')\n",
    "\n",
    "tc.assertEquals(1, 2, \"Replace this assert with meaningfull checks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature creation\n",
    "\n",
    "Create a new column \"antwerpen\" which is 1 for all stores in Antwerpen (province) and 0 for all others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here\n",
    "raise NotImplementedError(\"You need to develop this feature!\")\n",
    "\n",
    "df_clp[\"antwerpen\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict used car value\n",
    "\n",
    "A datascientist in our team made a basic model to predict car prices.  \n",
    "The model was saved to disk ('lgbr_cars.model') using joblib's dump fuctionality.  \n",
    "Documentation states the model is a LightGBM Regressor, trained using the sk-learn api.  \n",
    "\n",
    "**As engineer, your task it to expose this model as REST-api.** \n",
    "\n",
    "First, retrieve the model via the function below.  \n",
    "Change the path according to your setup.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here\n",
    "\n",
    "def retrieve_model(path):\n",
    "    raise NotImplementedError(\"You need to retrieve the trained model!\")\n",
    "    return trained_model\n",
    "\n",
    "lgbr_cars = retrieve_model(\"../../models/lgbr_cars.model\")\n",
    "\n",
    "tc.assertEqual(str(type(lgbr_cars)),\"<class 'lightgbm.sklearn.LGBMRegressor'>\", type(lgbr_cars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have your trained model, lets do a functional test based on the parameters below.  \n",
    "You have to present the parameters in this order.  \n",
    "\n",
    "* vehicleType: coupe\n",
    "* gearbox: manuell\n",
    "* powerPS: 190\n",
    "* model: NaN\n",
    "* kilometer: 125000\n",
    "* monthOfRegistration: 5 \n",
    "* fuelType: diesel\n",
    "* brand: audi\n",
    "\n",
    "Based on these parameters, you should get a predicted value of 14026.35068804\n",
    "However, the model doesnt accept string inputs, see the integer encoding below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_input = [[3,1,190,-1,125000,5,3,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here\n",
    "\n",
    "def make_prediction(trained_model, single_input):\n",
    "    raise NotImplementedError(\"You need to predict the value!\")\n",
    "    return predicted_value\n",
    "\n",
    "predicted_value = make_prediction(lgbr_cars, model_test_input)\n",
    "\n",
    "tc.assertAlmostEqual(predicted_value, 14026.35, places=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you got this model up and running, we want you to **expose it as a rest api.**  \n",
    "We don't expect you to set up any authentication.  \n",
    "We're not looking for beautiful inputs, just make it work.  \n",
    "**Building this endpoint should NOT be done in a notebook, but in proper .py file(s)**\n",
    "\n",
    "Once its up and running, use it to predict the following input:\n",
    "* [-1,1,0,118,150000,0,1,38] ==> prediction should be 13920.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geospatial data exercise\n",
    "The goal of this exercise is to read in some data from a shape file and visualize it on a map\n",
    "- The map should be dynamic. I want to zoom in and out to see more interesting aspects of the map\n",
    "- We want you to visualize the statistical sectors within a distance of 2KM of your home location.\n",
    "\n",
    "Specific steps to take:\n",
    "- Read in the shape file\n",
    "- Transform to WGS coordinates\n",
    "- Create a distance function (Haversine)\n",
    "- Create variables for home_lat, home_lon and perimeter_distance\n",
    "- Calculate centroid for each nis district\n",
    "- Calculate the distance to home for each nis district centroid \n",
    "- Figure out which nis districts are near your home\n",
    "- Create dynamic zoomable map\n",
    "- Visualize the nis districts near you (centroid <2km away), on the map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports to help you along the way\n",
    "import geopandas as gpd\n",
    "import folium # you can use any viz library you prefer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 1: Reading in the data\n",
    "# get this file from https://statbel.fgov.be/sites/default/files/files/opendata/Statistische%20sectoren/sh_statbel_statistical_sectors_20200101.shp.zip \n",
    "df = gpd.read_file('../../data/external/shapefiles/AD_0_StatisticSector.shp')\n",
    "df = df.to_crs({'init': 'epsg:4326'}) # change projection to wgs84 \n",
    "\n",
    "# One of the data scientists discovered stackoverflow ;-) and copypasted something from https://gis.stackexchange.com/questions/166820/geopandas-return-lat-and-long-of-a-centroid-point\n",
    "# A data science engineer should be able to speed this next code up\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    df.loc[i,'centroid_lon'] = df.geometry.centroid.x.iloc[i]\n",
    "    df.loc[i,'centroid_lat'] = df.geometry.centroid.y.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some variables to indicate the location of your interest \n",
    "home_lat = NotImplemented\n",
    "home_lon = NotImplemented\n",
    "perimeter_distance = 2 # km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At some point we will need a distance function (google the Haversine formula, and implement it)\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    raise NotImplementedError('Implement haversine')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, implement some sanity checks for your distance function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement sanity checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a dynamical map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of the map goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
